{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_LSTM_Training_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FLfPLxaik70"
      },
      "source": [
        "#LSTM 一維時序信號訓練及預測範例  \n",
        "歐尼克斯實境互動工作室 OmniXRI Jack, 2021.6.15  \n",
        "參考資料：Github lucko515/tesla-stocks-prediction  \n",
        "https://github.com/lucko515/tesla-stocks-prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY31yIsFlIU6"
      },
      "source": [
        "強迫Colab使用TensorFlow 1.x版以符合後續程式運行    \n",
        "宣告必要使用函式庫  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ami61V8Tkjtl"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__) # 確認TensorFlow版本"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RR1B7bblpn-"
      },
      "source": [
        "#1.下載資料集並進行預處理\n",
        "將資料集讀入並顯示開頭數筆完整資料  \n",
        "只抽取'Close'一欄資料作為後續範例使用並顯示資料集筆數  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idkltVYYkj8X"
      },
      "source": [
        "# 下載測試資料集  \n",
        "# 使用 !wget https://raw.githubusercontent.com/lucko515/tesla-stocks-prediction/master/tesla_stocks.csv\n",
        "# 取代 !wget https://github.com/lucko515/tesla-stocks-prediction/blob/master/tesla_stocks.csv\n",
        "\n",
        "!wget -N https://raw.githubusercontent.com/lucko515/tesla-stocks-prediction/master/tesla_stocks.csv\n",
        "!ls\n",
        "\n",
        "# 列出資料集完整內容\n",
        "#!cat tesla_stocks.csv\n",
        "\n",
        "# 讀取完整資料集\n",
        "tesla_stocks = pd.read_csv('tesla_stocks.csv')\n",
        "# 顯示頭幾筆完整資料\n",
        "tesla_stocks.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdiw14DM1Q6D"
      },
      "source": [
        "# 只抽取'Close'欄位資料作為後續使用\n",
        "data_to_use = tesla_stocks['Close'].values\n",
        "# 列出資料集筆數\n",
        "print('Total number of days in the dataset: {}'.format(len(data_to_use)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhxticQNnmoi"
      },
      "source": [
        "#2.將資料正規化並繪製圖示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l0cndP1kkHW"
      },
      "source": [
        "# 將資料正規化\n",
        "scaler = StandardScaler()\n",
        "scaled_dataset = scaler.fit_transform(data_to_use.reshape(-1, 1))\n",
        "# 繪製原始資料\n",
        "plt.figure(figsize=(12,7), frameon=False, facecolor='brown', edgecolor='blue')\n",
        "plt.title('Scaled TESLA stocks from August 2014 to August 2017')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Scaled value of stocks')\n",
        "plt.plot(scaled_dataset, label='Stocks data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGp5hKeoojua"
      },
      "source": [
        "#window_data()函式\n",
        "以移動視窗方式提取輸入及輸出資料，以利後續訓練及驗證用。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr7BsehXlC_T"
      },
      "source": [
        "def window_data(data, window_size):\n",
        "    X = [] # 取得輸入資料，window_size筆資料為一組\n",
        "    y = [] # 取得輸出資料，window_size後的一筆\n",
        "    \n",
        "    i = 0\n",
        "    while (i + window_size) <= len(data) - 1:\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size])\n",
        "        \n",
        "        i += 1\n",
        "    assert len(X) == len(y)\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AOsisxqurh"
      },
      "source": [
        "宣告程式所需主要參數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSggqvzaqhCM"
      },
      "source": [
        "epochs = 200 # 訓練次數\n",
        "batch_size = 7 # 資料批次提取數量\n",
        "train_amount = 700 # 訓練資料數量"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z7frNUtsC4_"
      },
      "source": [
        "#3.取得訓練和測試資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVLFRMGZlGIs"
      },
      "source": [
        "# 取得訓練及測試資料\n",
        "X, y = window_data(scaled_dataset, batch_size)\n",
        "# 取得train_amount筆數資料作為訓練集\n",
        "X_train  = np.array(X[:train_amount])\n",
        "y_train = np.array(y[:train_amount])\n",
        "# 剩下的部份作為測試集\n",
        "X_test = np.array(X[train_amount:])\n",
        "y_test = np.array(y[train_amount:])\n",
        "# 列出資料集數量\n",
        "print(\"X_train size: {}\".format(X_train.shape))\n",
        "print(\"y_train size: {}\".format(y_train.shape))\n",
        "print(\"X_test size: {}\".format(X_test.shape))\n",
        "print(\"y_test size: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmTx6wksr_Uw"
      },
      "source": [
        "#LSTM_cell()函式  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6uCi1CJlR43"
      },
      "source": [
        "def LSTM_cell(hidden_layer_size, batch_size,number_of_layers, dropout=True, dropout_rate=0.8):\n",
        "    \n",
        "    layer = tf.contrib.rnn.BasicLSTMCell(hidden_layer_size)\n",
        "    \n",
        "    if dropout:\n",
        "        layer = tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout_rate)\n",
        "        \n",
        "    cell = tf.contrib.rnn.MultiRNNCell([layer]*number_of_layers)\n",
        "    \n",
        "    init_state = cell.zero_state(batch_size, tf.float32)\n",
        "    \n",
        "    return cell, init_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUgT4AC6wnyR"
      },
      "source": [
        "#output_layer()函式  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkHLSHu0lT6m"
      },
      "source": [
        "def output_layer(lstm_output, in_size, out_size):\n",
        "    \n",
        "    x = lstm_output[:, -1, :]\n",
        "    print(x)\n",
        "    weights = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.05), name='output_layer_weights')\n",
        "    bias = tf.Variable(tf.zeros([out_size]), name='output_layer_bias')\n",
        "    \n",
        "    output = tf.matmul(x, weights) + bias\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKKpBuWHw5vH"
      },
      "source": [
        "#opt_loss()函式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v4PE21_lX0h"
      },
      "source": [
        "def opt_loss(logits, targets, learning_rate, grad_clip_margin):\n",
        "    \n",
        "    losses = []\n",
        "    for i in range(targets.get_shape()[0]):\n",
        "        losses.append([(tf.pow(logits[i] - targets[i], 2))])\n",
        "        \n",
        "    loss = tf.reduce_sum(losses)/(2*batch_size)\n",
        "    \n",
        "    #Cliping the gradient loss\n",
        "    gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "    clipper_, _ = tf.clip_by_global_norm(gradients, grad_clip_margin)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    train_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "    return loss, train_optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDEykbplxCdk"
      },
      "source": [
        "#StockPredictionRNN()類別函式\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_l0N4KWlZGJ"
      },
      "source": [
        "class StockPredictionRNN(object):\n",
        "    \n",
        "    def __init__(self, learning_rate=0.001, batch_size=7, hidden_layer_size=512, number_of_layers=1, \n",
        "                 dropout=True, dropout_rate=0.8, number_of_classes=1, gradient_clip_margin=4, window_size=7):\n",
        "    \n",
        "        self.inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1], name='input_data')\n",
        "        self.targets = tf.placeholder(tf.float32, [batch_size, 1], name='targets')\n",
        "\n",
        "        cell, init_state = LSTM_cell(hidden_layer_size, batch_size, number_of_layers, dropout, dropout_rate)\n",
        "\n",
        "        outputs, states = tf.nn.dynamic_rnn(cell, self.inputs, initial_state=init_state)\n",
        "\n",
        "        self.logits = output_layer(outputs, hidden_layer_size, number_of_classes)\n",
        "\n",
        "        self.loss, self.opt = opt_loss(self.logits, self.targets, learning_rate, gradient_clip_margin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugKcyKNxxazO"
      },
      "source": [
        "設定model, session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1wEmcS4lcX0"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "model = StockPredictionRNN()\n",
        "\n",
        "session =  tf.Session()\n",
        "session.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnCmpjHxf-I"
      },
      "source": [
        "#開始訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw-bezzyw5MC"
      },
      "source": [
        "import time\n",
        "\n",
        "time_start = time.time() #開始計時\n",
        "\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "        \n",
        "        o, c, _ = session.run([model.logits, model.loss, model.opt], feed_dict={model.inputs:X_batch, model.targets:y_batch})\n",
        "        \n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 10) == 0: # 每隔10次列出目前損失率，次數可自行調整\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))\n",
        "\n",
        "time_end = time.time() # 結束計時\n",
        "time_c= time_end - time_start # 計算執行所花時間\n",
        "print('time cost', time_c, 's') # 列出總共花費時間"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efHnWad_yUt7"
      },
      "source": [
        "取得正規化後原始資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcrcEJMyx76b"
      },
      "source": [
        "sup =[]\n",
        "for i in range(len(traind_scores)):\n",
        "    for j in range(len(traind_scores[i])):\n",
        "        sup.append(traind_scores[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI229aPgyeoC"
      },
      "source": [
        "取得測試資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEW6nRrS7xNL"
      },
      "source": [
        "tests = []\n",
        "i = 0\n",
        "while i+batch_size <= len(X_test):\n",
        "    \n",
        "    o = session.run([model.logits], feed_dict={model.inputs:X_test[i:i+batch_size]})\n",
        "    i += batch_size\n",
        "    tests.append(o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8I9-4JBynPv"
      },
      "source": [
        "產生最後測試資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gcOmhqZ88OD"
      },
      "source": [
        "tests_new = []\n",
        "for i in range(len(tests)):\n",
        "    for j in range(len(tests[i][0])):\n",
        "        tests_new.append(tests[i][0][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtc65qg7zDJ2"
      },
      "source": [
        "分別產生訓練和測試結果資料序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWbtrJiX7oOl"
      },
      "source": [
        "test_results = []\n",
        "for i in range(749):\n",
        "    if i >= 701:\n",
        "        test_results.append(tests_new[i-701])\n",
        "    else:\n",
        "        test_results.append(None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "998N-FBBzUPe"
      },
      "source": [
        "#繪製出結果\n",
        "藍色線為原始資料正規化內容，橙色線訓練集資料，綠色為測試輸出結果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIkhSYkyIzZ"
      },
      "source": [
        "plt.figure(figsize=(16, 7))\n",
        "plt.plot(scaled_dataset, label='Original data')\n",
        "plt.plot(sup, label='Training data')\n",
        "plt.plot(test_results, label='Testing data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoaFHe5A7cYw"
      },
      "source": [
        "plt.figure(figsize=(16, 7))\n",
        "plt.plot(epoch_loss, label='Epoch Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avQGQJfwzagz"
      },
      "source": [
        "session.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}